#!/bin/bash

# Exit immediately if a command exits with a non-zero status
set -e

# Define project name
PROJECT_NAME="observability-bot"

# Step 1: Create Folder Structure
echo "Creating folder structure for the project..."
mkdir -p $PROJECT_NAME/backend
mkdir -p $PROJECT_NAME/frontend
mkdir -p $PROJECT_NAME/models

# Step 2: Create Boilerplate Files
echo "Creating boilerplate files..."

# Backend Files
cat <<EOF > $PROJECT_NAME/backend/main.py
from fastapi import FastAPI
from backend.database import initialize_db, get_connection
from backend.gpt_model import generate_answer
from backend.confluence_sync import sync_confluence_to_db

app = FastAPI()

@app.on_event("startup")
def startup_event():
    initialize_db()

@app.get("/ask")
def ask_question(query: str):
    conn = get_connection()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT title, content
        FROM wiki_content
        WHERE content ILIKE %s
        LIMIT 5;
    """, (f"%{query}%",))
    results = cursor.fetchall()
    cursor.close()
    conn.close()

    if not results:
        return {"answer": "No relevant information found in the Wiki."}

    context = "\n\n".join([row[1] for row in results])
    answer = generate_answer(query, context)
    return {"answer": answer}
EOF

cat <<EOF > $PROJECT_NAME/backend/database.py
import psycopg2

DB_CONFIG = {
    "host": "localhost",
    "port": 5432,
    "database": "observability_faq",
    "user": "admin",
    "password": "admin123"
}

def get_connection():
    return psycopg2.connect(**DB_CONFIG)

def initialize_db():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS wiki_content (
            id SERIAL PRIMARY KEY,
            page_id TEXT NOT NULL,
            title TEXT NOT NULL,
            content TEXT NOT NULL
        );
    """)
    conn.commit()
    cursor.close()
    conn.close()
EOF

cat <<EOF > $PROJECT_NAME/backend/confluence_sync.py
from atlassian import Confluence
from backend.database import get_connection

CONFLEUNCE_URL = "https://wiki.coupang.net/"
CONFLUENCE_USERNAME = "akdubey"
CONFLUENCE_API_TOKEN = "abcdefgh123"
WIKI_SPACE = "MST"

confluence = Confluence(
    url=CONFLEUNCE_URL,
    username=CONFLUENCE_USERNAME,
    token=CONFLUENCE_API_TOKEN
)

def sync_confluence_to_db():
    conn = get_connection()
    cursor = conn.cursor()

    pages = confluence.get_all_pages_from_space(
        space=WIKI_SPACE, start=0, limit=100, expand="body.storage"
    )
    for page in pages:
        page_id = page["id"]
        title = page["title"]
        content = confluence.get_page_by_id(page_id, expand="body.storage")["body"]["storage"]["value"]

        cursor.execute("""
            INSERT INTO wiki_content (page_id, title, content)
            VALUES (%s, %s, %s)
            ON CONFLICT (page_id) DO UPDATE SET
                title = EXCLUDED.title,
                content = EXCLUDED.content;
        """, (page_id, title, content))
    conn.commit()
    cursor.close()
    conn.close()
EOF

cat <<EOF > $PROJECT_NAME/backend/gpt_model.py
from transformers import pipeline

qa_pipeline = pipeline("question-answering", model="distilbert-base-cased-distilled-squad")

def generate_answer(question, context):
    response = qa_pipeline(question=question, context=context)
    return response["answer"]
EOF

# Frontend Files
cat <<EOF > $PROJECT_NAME/frontend/index.html
<!DOCTYPE html>
<html>
<head>
    <title>Observability FAQ Bot</title>
</head>
<body>
    <h1>Observability FAQ Bot</h1>
    <div id="chatbox"></div>
    <input type="text" id="query" placeholder="Ask a question..." />
    <button onclick="askQuestion()">Ask</button>

    <script src="app.js"></script>
</body>
</html>
EOF

cat <<EOF > $PROJECT_NAME/frontend/app.js
async function askQuestion() {
    const query = document.getElementById("query").value;
    const response = await fetch(\`http://127.0.0.1:8000/ask?query=\${encodeURIComponent(query)}\`);
    const data = await response.json();

    const chatbox = document.getElementById("chatbox");
    chatbox.innerHTML += \`<p><strong>User:</strong> \${query}</p>\`;
    chatbox.innerHTML += \`<p><strong>Bot:</strong> \${data.answer}</p>\`;
}
EOF

# Docker Compose File for PostgreSQL
cat <<EOF > $PROJECT_NAME/docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres
    container_name: postgres-db
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin123
      POSTGRES_DB: observability_faq
    ports:
      - "5432:5432"
EOF

# Requirements File
cat <<EOF > $PROJECT_NAME/requirements.txt
fastapi
uvicorn
psycopg2-binary
atlassian-python-api
transformers
EOF

# Step 3: Download and Configure NLP Model
echo "Downloading and configuring NLP models..."
python3 -m pip install -r $PROJECT_NAME/requirements.txt
python3 -c "from transformers import pipeline; pipeline('question-answering', model='distilbert-base-cased-distilled-squad')"

echo "Setup complete. Navigate to $PROJECT_NAME and start developing!"
